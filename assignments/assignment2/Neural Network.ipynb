{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is EPRUPETW1824\n",
      " Volume Serial Number is 4E55-CD70\n",
      "\n",
      " Directory of C:\\Users\\Ilya_Starikov\\PycharmProjects\\self-education\\dlcourse_ai\\assignments\\assignment1\n",
      "\n",
      "12/16/2019  12:42 PM    <DIR>          .\n",
      "12/16/2019  12:42 PM    <DIR>          ..\n",
      "12/11/2019  03:03 PM    <DIR>          .ipynb_checkpoints\n",
      "12/11/2019  03:03 PM    <DIR>          data\n",
      "11/26/2019  03:46 PM             2,259 dataset.py\n",
      "11/26/2019  03:46 PM               139 download_data.sh\n",
      "12/12/2019  05:58 PM             1,846 gradient_check.py\n",
      "11/27/2019  05:11 PM           156,834 KNN.ipynb\n",
      "11/27/2019  01:59 PM             5,704 knn.py\n",
      "12/16/2019  12:42 PM            50,020 Linear classifier.ipynb\n",
      "12/07/2019  11:00 AM             6,688 linear_classifer.py\n",
      "11/27/2019  04:58 PM             1,530 metrics.py\n",
      "11/26/2019  03:46 PM             1,093 README.md\n",
      "11/26/2019  03:46 PM                26 requirements.txt\n",
      "12/11/2019  03:03 PM    <DIR>          __pycache__\n",
      "              10 File(s)        226,139 bytes\n",
      "               5 Dir(s)  182,025,650,176 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir ..\\\\assignment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "FOLDER = '..\\\\assignment1\\\\data'\n",
    "train_X, train_y, test_X, test_y = load_svhn(FOLDER, max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import ReLULayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.dot(test, 2)\n",
    "v2 = np.sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from layers import FullyConnectedLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "\n",
      " dW\n",
      "Gradient check passed!\n",
      "\n",
      " dB\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "print('\\n dW')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "print('\\n dB')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for FC1_W\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-cb59275d7c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# TODO Now implement backward pass and aggregate all of the params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcheck_model_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\self-education\\dlcourse_ai\\assignments\\assignment2\\gradient_check.py\u001b[0m in \u001b[0;36mcheck_model_gradient\u001b[1;34m(model, X, y, delta, tol, debug)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhelper_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\self-education\\dlcourse_ai\\assignments\\assignment2\\gradient_check.py\u001b[0m in \u001b[0;36mcheck_gradient\u001b[1;34m(f, x, delta, tol, debug)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mx_d_up\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_d_up\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mfx_d_up\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_d_up\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mnumeric_grad_at_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfx_d_up\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfx_d_low\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gradient_check import check_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc1_w\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_b\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_w\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_b\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FC1_W': <layers.Param at 0x1fe68277488>,\n",
       " 'FC1_B': <layers.Param at 0x1fe682774c8>,\n",
       " 'FC2_W': <layers.Param at 0x1fe68277a08>,\n",
       " 'FC2_B': <layers.Param at 0x1fe68277e88>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = {}\n",
    "for name, param in model.params().items():\n",
    "    optim[name] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FC1_W': <layers.Param object at 0x000001FE021F2188>}\n",
      "{'FC1_B': <layers.Param object at 0x000001FE021F2FC8>}\n",
      "{'FC2_W': <layers.Param object at 0x000001FE021F2508>}\n",
      "{'FC2_B': <layers.Param object at 0x000001FE021F25C8>}\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.params().items():\n",
    "    print({n: p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:2.302448, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2, num_epochs=5)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fe3c5f8ec8>]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH: 0\n",
      "PREDICT STAGE\n",
      "train predict \n",
      "\n",
      "PREDICTION\n",
      "[ 597 1770 1334 1028  891  838  688  692  601  561]\n",
      "[   0 9000]\n",
      "val predict \n",
      "\n",
      "PREDICTION\n",
      "[ 49 206 140 147  93  90  78  76  61  60]\n",
      "[   0 1000]\n",
      "Epoch: 0, Loss:2.268982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      " EPOCH: 1\n",
      "PREDICT STAGE\n",
      "train predict \n",
      "\n",
      "PREDICTION\n",
      "[ 597 1770 1334 1028  891  838  688  692  601  561]\n",
      "[   0 9000]\n",
      "val predict \n",
      "\n",
      "PREDICTION\n",
      "[ 49 206 140 147  93  90  78  76  61  60]\n",
      "[   0 1000]\n",
      "Epoch: 1, Loss:2.265676, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      " EPOCH: 2\n",
      "PREDICT STAGE\n",
      "train predict \n",
      "\n",
      "PREDICTION\n",
      "[ 597 1770 1334 1028  891  838  688  692  601  561]\n",
      "[   0 9000]\n",
      "val predict \n",
      "\n",
      "PREDICTION\n",
      "[ 49 206 140 147  93  90  78  76  61  60]\n",
      "[   0 1000]\n",
      "Epoch: 2, Loss:2.265125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      " EPOCH: 3\n",
      "PREDICT STAGE\n",
      "train predict \n",
      "\n",
      "PREDICTION\n",
      "[ 597 1770 1334 1028  891  838  688  692  601  561]\n",
      "[   0 9000]\n",
      "val predict \n",
      "\n",
      "PREDICTION\n",
      "[ 49 206 140 147  93  90  78  76  61  60]\n",
      "[   0 1000]\n",
      "Epoch: 3, Loss:2.279395, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      " EPOCH: 4\n",
      "PREDICT STAGE\n",
      "train predict \n",
      "\n",
      "PREDICTION\n",
      "[ 597 1770 1334 1028  891  838  688  692  601  561]\n",
      "[   0 9000]\n",
      "val predict \n",
      "\n",
      "PREDICTION\n",
      "[ 49 206 140 147  93  90  78  76  61  60]\n",
      "[   0 1000]\n",
      "Epoch: 4, Loss:2.253603, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99, num_epochs=5)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3072)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_X[:20, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = normalize(train_X[:20], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(norm_x[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:20.797530, Train accuracy: 0.171444, val accuracy: 0.175000\n",
      "Epoch: 5, Loss:9.949386, Train accuracy: 0.207222, val accuracy: 0.210000\n",
      "Epoch: 10, Loss:5.739296, Train accuracy: 0.203222, val accuracy: 0.208000\n",
      "Epoch: 15, Loss:3.779118, Train accuracy: 0.197778, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:22.661903, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch: 5, Loss:12.431909, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch: 10, Loss:7.495170, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch: 15, Loss:4.585588, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 20, Loss:3.359785, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 25, Loss:2.247959, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 30, Loss:1.929583, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 35, Loss:1.800376, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 40, Loss:1.702572, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 45, Loss:1.584264, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 50, Loss:1.479005, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 55, Loss:1.326876, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 60, Loss:1.370120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 65, Loss:1.386965, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 70, Loss:1.253648, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 75, Loss:1.257592, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 80, Loss:1.126204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 85, Loss:1.300829, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 90, Loss:1.462299, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 95, Loss:1.463050, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 100, Loss:1.249736, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 105, Loss:1.267205, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 110, Loss:1.168096, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 115, Loss:1.537601, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 120, Loss:1.257135, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 125, Loss:1.284173, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 130, Loss:1.435967, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 135, Loss:1.333513, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 140, Loss:1.325544, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 145, Loss:1.278924, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:24.160133, Train accuracy: 0.400000, val accuracy: 0.266667\n",
      "Epoch: 5, Loss:15.720726, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch: 10, Loss:8.853191, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 15, Loss:4.677766, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  2. , -3. ,  0. ],\n",
       "       [-2. ,  2. ,  0.5,  1. ],\n",
       "       [ 1. ,  1. ,  2. ,  0. ]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([[ 1,  2, -3,  0],\n",
    "                   [ -2,  2, 0.5,  1],\n",
    "                   [ 1,  1,  2,  0]])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0000001 , 0.2500001 , 4.5000001 , 0.33333343])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((x_test - mean)**2, axis=0)+1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710676,  0.70710662, -1.35244737, -0.70710662],\n",
       "       [-1.41421353,  0.70710662,  0.31822291,  1.41421324],\n",
       "       [ 0.70710676, -1.41421324,  1.03422446, -0.70710662]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(x_test, axis=0)  # shape == (X.shape[1], )\n",
    "sig = np.sqrt(np.mean((x_test - mean)**2, axis=0)+1e-7)\n",
    "out = (x_test - mean) / sig\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = np.round(0.1**np.arange(1, 5), 8)\n",
    "lr = np.random.choice(learning_rates)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "START\n",
      "PARAMS: lr - 0.01, reg_strenght - 0.001, batch size - 64, hidden_size - 100\n",
      "Epoch: 0, Loss:2.019098, Train accuracy: 0.388556, val accuracy: 0.402000\n",
      "Epoch: 5, Loss:1.278629, Train accuracy: 0.710889, val accuracy: 0.681000\n",
      "Epoch: 10, Loss:1.007386, Train accuracy: 0.766889, val accuracy: 0.736000\n",
      "Epoch: 15, Loss:1.146120, Train accuracy: 0.799444, val accuracy: 0.727000\n",
      "Epoch: 20, Loss:0.900739, Train accuracy: 0.829556, val accuracy: 0.758000\n",
      "Epoch: 25, Loss:0.825688, Train accuracy: 0.835889, val accuracy: 0.745000\n",
      "Epoch: 30, Loss:0.753128, Train accuracy: 0.859222, val accuracy: 0.764000\n",
      "Epoch: 35, Loss:0.653961, Train accuracy: 0.878222, val accuracy: 0.769000\n",
      "Epoch: 40, Loss:0.813306, Train accuracy: 0.870222, val accuracy: 0.757000\n",
      "Epoch: 45, Loss:0.705066, Train accuracy: 0.872889, val accuracy: 0.746000\n",
      "Epoch: 50, Loss:0.909892, Train accuracy: 0.897444, val accuracy: 0.767000\n",
      "Epoch: 55, Loss:0.705901, Train accuracy: 0.890000, val accuracy: 0.758000\n",
      "Epoch: 60, Loss:0.525649, Train accuracy: 0.901889, val accuracy: 0.774000\n",
      "Epoch: 65, Loss:0.892505, Train accuracy: 0.904556, val accuracy: 0.772000\n",
      "Epoch: 70, Loss:0.786702, Train accuracy: 0.908444, val accuracy: 0.769000\n",
      "Epoch: 75, Loss:0.823103, Train accuracy: 0.918000, val accuracy: 0.778000\n",
      "Epoch: 80, Loss:0.671818, Train accuracy: 0.915444, val accuracy: 0.784000\n",
      "Epoch: 85, Loss:0.588371, Train accuracy: 0.925667, val accuracy: 0.778000\n",
      "Epoch: 90, Loss:0.699594, Train accuracy: 0.896778, val accuracy: 0.759000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [0.01]\n",
    "reg_strength = [0.001]  # np.round(0.1**np.arange(1, 5), 8)\n",
    "learning_rate_decay = 0.999  # 0.5 # 0.999\n",
    "hidden_layer_size = [100, 128]\n",
    "num_epochs = 101\n",
    "batch_size = [64]\n",
    "\n",
    "# add batch_normalization\n",
    "# add decy by epoch each 5 with lr/(1 + decay*epoch_n)  # do not work\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "\n",
    "# for n in range(10):\n",
    "    \n",
    "for h in hidden_layer_size:\n",
    "    print(\"\\nSTART\")\n",
    "    lr = np.random.choice(learning_rates)\n",
    "    reg = np.random.choice(reg_strength)\n",
    "    batch = np.random.choice(batch_size)\n",
    "    hidden_size = h  # np.random.choice(hidden_layer_size)\n",
    "    print(f\"PARAMS: lr - {lr}, reg_strenght - {reg}, batch size - {batch}, hidden_size - {hidden_size}\")\n",
    "    \n",
    "    model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=hidden_size, reg=reg)\n",
    "    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(),\n",
    "                      batch_size=batch,\n",
    "                      num_epochs=num_epochs, \n",
    "                      learning_rate=lr, \n",
    "                      learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "    loss, train, val = trainer.fit()\n",
    "    \n",
    "    if val[-1] > best_val_accuracy:\n",
    "        print(f\"\\n NEW best val accuracy: {val[-1]} \"\n",
    "              f\"PARAMS: lr - {lr}, reg_strenght - {reg}, batch size - {batch}, hidden_size - {hidden_size}\")\n",
    "        best_val_accuracy = val[-1]\n",
    "        loss_history = loss\n",
    "        train_history = train\n",
    "        val_history = val\n",
    "        best_classifier = model\n",
    "        best_params = {'lr': lr,\n",
    "                       'reg_strenght': reg,\n",
    "                       'batch size': batch,\n",
    "                       'hidden_size': hidden_size}\n",
    "        \n",
    "    print(\"END \\n\")\n",
    "        \n",
    "\n",
    "# best_val_accuracy = np.max(val)\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
    "print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.661000\n"
     ]
    }
   ],
   "source": [
    "best_classifier = model\n",
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
